以下是用 Python 编写接口调用、下载文件到指定目录并计算耗时的完整代码，包含详细注释和优化：

```python
import os
import time
import requests
from tqdm import tqdm  # 进度条库（需安装：pip install tqdm）

def download_file(url: str, save_dir: str, filename: str = None) -> float:
    """
    下载文件到指定目录并返回耗时
    
    :param url: 文件下载地址
    :param save_dir: 文件保存目录
    :param filename: 保存文件名（可选，默认从URL提取）
    :return: 下载耗时（秒）
    """
    # 确保目录存在
    os.makedirs(save_dir, exist_ok=True)
    
    # 获取文件名
    if not filename:
        filename = os.path.basename(url).split("?")[0]  # 处理带参数的URL
    
    save_path = os.path.join(save_dir, filename)
    
    try:
        # 发送HEAD请求获取文件大小（用于进度条）
        head_resp = requests.head(url, allow_redirects=True)
        file_size = int(head_resp.headers.get('Content-Length', 0))
        
        # 记录开始时间
        start_time = time.perf_counter()
        
        # 流式下载文件
        with requests.get(url, stream=True) as response:
            response.raise_for_status()  # 检查HTTP错误
            
            # 初始化进度条
            progress = tqdm(
                total=file_size,
                unit='B',
                unit_scale=True,
                desc=f"下载 {filename}",
                ncols=100  # 进度条宽度
            )
            
            # 写入文件
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:  # 过滤keep-alive chunks
                        f.write(chunk)
                        progress.update(len(chunk))
            
            progress.close()
            
        # 计算耗时
        elapsed = time.perf_counter() - start_time
        print(f"下载完成！保存路径：{save_path}")
        print(f"文件大小：{file_size / 1024 / 1024:.2f} MB")
        print(f"耗时：{elapsed:.2f} 秒 | 平均速度：{file_size / elapsed / 1024 / 1024:.2f} MB/s")
        return elapsed
        
    except Exception as e:
        # 清理未完成文件
        if os.path.exists(save_path):
            os.remove(save_path)
        raise RuntimeError(f"下载失败: {str(e)}")

# 使用示例
if __name__ == "__main__":
    download_url = "https://example.com/largefile.zip"  # 替换为实际URL
    save_directory = "./downloads"  # 保存目录
    file_name = "dataset.zip"      # 自定义文件名（可选）
    
    try:
        time_cost = download_file(download_url, save_directory, file_name)
    except Exception as e:
        print(str(e))
```

### 代码特点说明

1. **智能文件名提取**  
   - 自动从URL中提取文件名，处理带参数的URL（如 `file.zip?token=abc`）
   - 支持自定义文件名

2. **流式下载优化**  
   - 使用 `stream=True` 避免内存爆炸
   - 分块写入（`chunk_size=8192`）平衡内存和IO效率

3. **进度显示**  
   - 通过 `tqdm` 显示实时进度条
   - 显示下载速度、剩余时间等关键信息

4. **异常处理**  
   - 自动删除未完成文件
   - 捕获所有异常并提供明确错误信息

5. **性能统计**  
   - 精确到毫秒的计时（`time.perf_counter()`）
   - 计算平均下载速度

6. **目录自动创建**  
   - 使用 `os.makedirs(..., exist_ok=True)` 自动创建目录

### 运行效果示例

```text
下载 dataset.zip: 100%|████████████| 256M/256M [00:12<00:00, 21.3MB/s]
下载完成！保存路径：./downloads/dataset.zip
文件大小：256.00 MB
耗时：12.34 秒 | 平均速度：20.75 MB/s
```

### 扩展优化建议

1. **断点续传**  
   添加以下代码实现断点续传：
   ```python
   file_size_downloaded = os.path.getsize(save_path) if os.path.exists(save_path) else 0
   headers = {"Range": f"bytes={file_size_downloaded}-"} if file_size_downloaded else None
   response = requests.get(url, headers=headers, stream=True)
   ```

2. **多线程下载**  
   使用 `concurrent.futures` 实现分块并行下载：
   ```python
   from concurrent.futures import ThreadPoolExecutor
   ```

3. **文件校验**  
   下载完成后验证文件完整性：
   ```python
   import hashlib
   def calculate_md5(file_path):
       # 计算文件MD5
   ```

4. **代理支持**  
   添加代理配置：
   ```python
   proxies = {
       'http': 'http://10.10.1.10:3128',
       'https': 'http://10.10.1.10:1080',
   }
   response = requests.get(url, proxies=proxies, stream=True)
   ```

### 环境要求

1. 安装依赖：
   ```bash
   pip install requests tqdm
   ```

2. 测试文件建议：
   - 小文件测试：`https://httpbin.org/stream-bytes/1024`
   - 大文件测试：`https://speed.hetzner.de/100MB.bin`

该代码可直接用于生产环境，通过合理的异常处理和性能优化，能够稳定处理从KB级到GB级文件的下载任务。