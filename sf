以下是Spring Boot整合DuckDB实现数据持久化到S3的完整方案，包含代码实现和关键配置：

1. 添加依赖

<dependencies>
    <!-- Spring Boot Starter -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-jdbc</artifactId>
    </dependency>
    
    <!-- DuckDB JDBC -->
    <dependency>
        <groupId>org.duckdb</groupId>
        <artifactId>duckdb_jdbc</artifactId>
        <version>0.10.0</version>
    </dependency>
    
    <!-- AWS SDK for S3 -->
    <dependency>
        <groupId>software.amazon.awssdk</groupId>
        <artifactId>s3</artifactId>
        <version>2.20.0</version>
    </dependency>
</dependencies>


2. 配置文件 (application.yml)

s3:
  bucket: your-bucket-name
  region: your-region
  access-key: your-access-key
  secret-key: your-secret-key

duckdb:
  db-path: /tmp/duckdb_data.duckdb


3. DuckDB初始化配置类

@Configuration
public class DuckDBConfig {

    @Value("classpath:httpfs.duckdb_extension")
    private Resource httpfsExtension;

    @Value("${duckdb.db-path}")
    private String dbPath;

    @Bean
    public DataSource duckdbDataSource() throws IOException {
        // 将httpfs扩展复制到临时目录
        Path tempExtension = Files.createTempFile("httpfs", ".duckdb_extension");
        Files.copy(httpfsExtension.getInputStream(), tempExtension, StandardCopyOption.REPLACE_EXISTING);

        DuckDBDataSource dataSource = new DuckDBDataSource(dbPath);
        try (Connection conn = dataSource.getConnection();
             Statement stmt = conn.createStatement()) {
            
            // 加载本地httpfs扩展
            stmt.execute("SET extension_path='" + tempExtension.toString() + "'");
            stmt.execute("LOAD 'httpfs'");
            
            // 设置S3凭证
            stmt.execute("SET s3_region='${s3.region}'");
            stmt.execute("SET s3_access_key_id='${s3.access-key}'");
            stmt.execute("SET s3_secret_access_key='${s3.secret-key}'");
        }
        return dataSource;
    }
}


4. 数据服务层

@Service
public class DataService {

    private final JdbcTemplate jdbcTemplate;
    private final String s3Bucket;

    public DataService(DataSource dataSource, @Value("${s3.bucket}") String s3Bucket) {
        this.jdbcTemplate = new JdbcTemplate(dataSource);
        this.s3Bucket = s3Bucket;
    }

    // 从API获取数据并存储到S3
    public void fetchAndStoreData(String apiUrl, String s3Path) {
        // 1. 从API获取数据 (使用RestTemplate或WebClient)
        List<Map<String, Object>> apiData = fetchFromApi(apiUrl);

        // 2. 创建临时表
        jdbcTemplate.execute("CREATE TEMP TABLE temp_data AS SELECT * FROM apiData");

        // 3. 导出为Parquet到S3
        String exportSql = String.format(
            "COPY (SELECT * FROM temp_data) TO 's3://%s/%s.parquet' (FORMAT PARQUET)",
            s3Bucket, s3Path
        );
        jdbcTemplate.execute(exportSql);
    }

    // 从S3读取数据
    public List<Map<String, Object>> readFromS3(String s3Path) {
        String query = String.format(
            "SELECT * FROM read_parquet('s3://%s/%s.parquet')",
            s3Bucket, s3Path
        );
        return jdbcTemplate.queryForList(query);
    }

    private List<Map<String, Object>> fetchFromApi(String apiUrl) {
        // 实现API调用逻辑，返回结构化数据
        // 示例使用伪代码
        RestTemplate restTemplate = new RestTemplate();
        return restTemplate.getForObject(apiUrl, List.class);
    }
}


5. 使用示例

@RestController
@RequestMapping("/data")
public class DataController {

    private final DataService dataService;

    public DataController(DataService dataService) {
        this.dataService = dataService;
    }

    @PostMapping("/sync")
    public ResponseEntity<String> syncData() {
        dataService.fetchAndStoreData("https://api.example.com/data", "daily_data_202310");
        return ResponseEntity.ok("Data synced to S3");
    }

    @GetMapping("/{path}")
    public List<Map<String, Object>> getData(@PathVariable String path) {
        return dataService.readFromS3(path);
    }
}


关键实现细节：

1. HTTPFS扩展加载：

  ◦ 将resource目录下的httpfs扩展复制到临时目录

  ◦ 使用SET extension_path和LOAD命令加载扩展

2. S3配置：

  ◦ 通过DuckDB的SET命令配置S3凭证

  ◦ 使用s3://协议直接访问S3存储

3. 数据流转：

graph LR
A[第三方API] --> B(Spring Boot应用)
B --> C[DuckDB临时表]
C --> D[S3 Parquet文件]
D --> E[查询接口]


4. Parquet文件管理：

  ◦ 使用COPY TO导出为Parquet格式

  ◦ 使用read_parquet()函数直接查询S3文件

注意事项：

1. 扩展文件兼容性：

  ◦ 确保resource目录下的httpfs扩展与运行环境架构匹配

  ◦ 文件命名应为httpfs.duckdb_extension

2. 临时表使用：

  ◦ 使用TEMP TABLE避免持久化到本地磁盘

  ◦ 数据直接通过内存流转到S3

3. S3路径格式：

  ◦ 使用s3://bucket-name/path/to/file.parquet格式

  ◦ 不需要文件后缀但建议添加.parquet明确类型

4. 安全建议：

  ◦ 使用IAM角色替代硬编码密钥（生产环境）

  ◦ 添加S3存储桶策略限制访问

此方案实现了完整的端到端数据管道，从API获取数据到S3存储，再到数据查询，全部通过DuckDB在Spring Boot应用中完成。